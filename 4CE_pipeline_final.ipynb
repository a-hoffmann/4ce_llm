{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4CE pipeline final\n",
    "\n",
    "- This notebook:\n",
    "1. Takes the content of each site's submitted documents\n",
    "2. Creates and appends a prompt of 14 questions to the text body of each note\n",
    "3. Submits the above to a GPT-4 instance hosted on Azure\n",
    "4. Compiles the results into a spreadsheet for each site\n",
    "- The filetypes can be `.txt, .pdf`\n",
    "- Each Azure deployment may have a different name for the inference model used\n",
    "- the outputted spreadsheets contains the full details of the request and response for each note\n",
    "\n",
    "- The `.env` file must contain information about the endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import tiktoken\n",
    "\n",
    "encoding = tiktoken.encoding_for_model(\"gpt-4\")\n",
    "\n",
    "path = \"../../Data/\" # folder containing the patient notes\n",
    "\n",
    "supfolders = [f for f in os.listdir(path)]\n",
    "\n",
    "#remove the folders we don't want\n",
    "supfolders.remove('.DS_Store')\n",
    "supfolders.remove('Zips')\n",
    "\n",
    "dirnames = []\n",
    "\n",
    "for f in supfolders:\n",
    "    dirnames.append(f + '/' + [sf for sf in os.listdir(f\"{path}/{f}\") if '.' not in sf][0])\n",
    "    \n",
    "system_prompt = \"You are a medical assistant.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dirnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pypdf import PdfReader\n",
    "import chardet\n",
    "import re\n",
    "\n",
    "files = []\n",
    "print(\"Name\", \"Length\", \"Tokens\", \"Words\")\n",
    "tokens = {}\n",
    "bodies = {}\n",
    "for dname in dirnames:\n",
    "    temptokens = []\n",
    "    tempbodies = []\n",
    "    full_path = path + dname\n",
    "    files_per_site = []\n",
    "    for filename in os.listdir(full_path):\n",
    "        body=''\n",
    "        direct_path = os.path.join(full_path, filename)\n",
    "        if '.pdf' in direct_path:\n",
    "            reader = PdfReader(direct_path)\n",
    "            body = ''\n",
    "            for p in range(len(reader.pages)):\n",
    "                body += reader.pages[p].extract_text()\n",
    "            files_per_site.append(direct_path)\n",
    "        if '.txt' in direct_path:\n",
    "            with open(os.path.join(full_path, filename), 'rb') as f: # open in readonly mode\n",
    "                body = f.read()\n",
    "                body = body.decode(chardet.detect(body)['encoding']) # use chardet to find the right encoding\n",
    "                direct_path = f.name\n",
    "            files_per_site.append(direct_path)\n",
    "        else:\n",
    "            print(direct_path)\n",
    "            pass\n",
    "        if len(body)>0:\n",
    "            temptokens.append(len(encoding.encode(body)))\n",
    "            tempbodies.append(len(re.findall(r'\\w+', body)))\n",
    "    tokens[dname] = temptokens\n",
    "    bodies[dname]= tempbodies\n",
    "    files_per_site.sort()\n",
    "    files.append(files_per_site)\n",
    "    print(\"---------\")\n",
    "\n",
    "print(files)\n",
    "\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statistics\n",
    "import numpy as np\n",
    "\n",
    "print(\"----- \\nTokens\")\n",
    "\n",
    "for id in tokens:\n",
    "    data = tokens[id]\n",
    "    med = statistics.median(data)\n",
    "    q3, q1 = np.percentile(data, [75 ,25])\n",
    "    iqr = q3 - q1\n",
    "    print(id, f\"{med}, {iqr}\")\n",
    "\n",
    "print(\"----- \\nWords\")\n",
    "\n",
    "for id in bodies:\n",
    "    data = bodies[id]\n",
    "    med = statistics.median(data)\n",
    "    q3, q1 = np.percentile(data, [75 ,25])\n",
    "    iqr = q3 - q1\n",
    "    print(id, f\"{med}, {iqr}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we find that the note lengths are comfortably under the token limit, we can go ahead and submit these as-is in the API request."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import configparser\n",
    "\n",
    "config = configparser.ConfigParser()\n",
    "config.read(\"../config.ini\")\n",
    "\n",
    "openai.api_key = config[\"OpenAI\"][\"api_key\"]\n",
    "openai.api_type = config[\"OpenAI\"][\"api_type\"]\n",
    "openai.api_base = config[\"OpenAI\"][\"api_base\"]\n",
    "openai.api_version = config[\"OpenAI\"][\"api_version\"]\n",
    "\n",
    "print('Deployment IDs and capabilities:')\n",
    "deployment_id = None\n",
    "result = openai.Deployment.list()\n",
    "\n",
    "for deployment in result.data:\n",
    "    print(f\"{deployment['id']}: {openai.Model.retrieve(deployment['model'])['capabilities']}\")\n",
    "\n",
    "modelname = \"<your_model_name>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inclusion = [\"What is the patient's BMI?\",\n",
    "\"Is the patient within the age range of the study (18 to 65)?\",\n",
    "\"Was the primary reason for this visit to treat the patient for COVID-19 disease?\",\n",
    "\"\"\"Does the patient adhere to the inclusion criteria of the study? \n",
    " >>>>Inclusion criteria: Patients aged 18 to 65, both male and female, with obesity and history of or with active COVID.\n",
    " >>>>Exclusion criteria: Patients outside the age range, without obesity or COVID.\n",
    " If the answer is no, tell me which criteria it did not meet.\"\"\",\n",
    "\"Was the main reason for hospitalization covid? This includes patients who developed complications due to covid.\"]\n",
    "\n",
    "novsunknown = [\"Does the patient have covid on admission? If this is not available in the notes, return \\\"not found in notes\\\".\",\n",
    "\"Does the patient require immediate medical attention?\",\n",
    "\"Is the patient obese? which threshold/definition did you use to determine this?\",\n",
    "\"What is the patient's age?\"]\n",
    "\n",
    "hallucination = [\"What is the patient's gender?\",\n",
    "\"Is this an admission note?\",\n",
    "\"Does the patient have diabetes?\",\n",
    "\"\"\"Apply the prevailing USPSTF Guidelines for Prediabetes and Type 2 Diabetes to this patient. \n",
    "This guideline states: 'The USPSTF recommends screening for prediabetes and type 2 diabetes in adults aged 35 to 70 years who have overweight or obesity. Clinicians should offer or refer patients with prediabetes to effective preventive interventions.'\n",
    " Based on this guideline, should the clinician offer or refer this patient for preventive intervention? Provide reasons to support your answer. \"\"\"]\n",
    "\n",
    "typos = [\"Do you notice any inconsistencies or typos in the patient note? If you do, reprint them and specify of what kind they are.\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = inclusion + novsunknown + hallucination + typos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qbody = \"\"\n",
    "for q in range(len(questions)):\n",
    "    qbody += f\"{q+1}. {questions[q]}\\n\"\n",
    "\n",
    "print(qbody)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instructions = \"\"\"From the provided document below, answer the following questions: {}\n",
    "Return the list order number for each of your answers and make sure to briefly specify at the end whether you found the answer in the document or not.\n",
    " \n",
    "------\n",
    "{}\n",
    "------\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "from datetime import datetime\n",
    "import re\n",
    "\n",
    "for site in files:\n",
    "      tstamp = datetime.now().strftime('%Y-%m-%d %H꞉%M꞉%S')\n",
    "      site_id = site[0].replace(\"../../Data/\",\"\").split(\"/\")[0]\n",
    "      full_responses = pd.DataFrame(columns=[\"ID\", \"Document Size\", \"Input\", \"Output\", \"Tokens In\", \"Tokens Out\", \"Total Tokens\", \"Time\"])\n",
    "      for filename in site:\n",
    "            start_time = time.time()\n",
    "            storage = {}\n",
    "            if '.pdf' in filename:\n",
    "                  reader = PdfReader(filename)\n",
    "                  body = ''\n",
    "                  for p in range(len(reader.pages)):\n",
    "                        body += reader.pages[p].extract_text() + '\\n'\n",
    "            else:\n",
    "                  with open(filename, 'r', encoding=\"latin-1\") as f: # open in readonly mode\n",
    "                        storage[\"ID\"] = filename.split(\"/\")[-1].replace(\".pdf\",\"\")\n",
    "                        note_content = f.read()\n",
    "                        print(storage[\"ID\"])\n",
    "                        storage[\"Document Size\"] = len(note_content)\n",
    "                        storage[\"Input\"] = instructions.format(qbody, note_content)\n",
    "                        llm_call = openai.ChatCompletion.create(\n",
    "                              engine=modelname, # Model name specific to each Azure GPT-4 instance\n",
    "                              messages=[\n",
    "                              {\"role\": \"system\", \"content\": system_prompt},\n",
    "                              {\"role\": \"user\", \"content\": storage[\"Input\"]},\n",
    "                        ],     temperature=0.2,\n",
    "                              top_p=0.95,\n",
    "                              frequency_penalty=0,\n",
    "                              presence_penalty=0,\n",
    "                              stop=None)\n",
    "                        storage[\"Output\"] = llm_call.choices[0].message.content\n",
    "                        storage[\"Tokens In\"] = llm_call.usage.prompt_tokens\n",
    "                        storage[\"Tokens Out\"] = llm_call.usage.completion_tokens\n",
    "                        storage[\"Total Tokens\"] = llm_call.usage.total_tokens\n",
    "                        storage[\"Time\"] = time.time() - start_time\n",
    "\n",
    "                        full_responses.loc[len(full_responses)] = storage\n",
    "\n",
    "      #write the excel\n",
    "\n",
    "      for index, row in full_responses.iterrows():\n",
    "            indetails = pd.DataFrame(columns=[\"ID\"]+questions)\n",
    "            #split the ordered list up\n",
    "            ordered_responses = []\n",
    "            for i in range(1,len(questions)+1):\n",
    "                  if i == 1:\n",
    "                        ordered_responses.append(row.Output.split(f\"{i}. \")[1].split(f\"\\n{i+1}. \")[0])\n",
    "                  else:\n",
    "                        ordered_responses.append(row.Output.split(f\"\\n{i}. \")[1].split(f\"\\n{i+1}. \")[0])\n",
    "            \n",
    "            indetails.loc[len(indetails)] = [row.ID] + ordered_responses\n",
    "            # adding a row for the feedback\n",
    "            indetails.loc[len(indetails)] = [f\"Is the information available in the note?\"] + [\"\" for w in range(len(questions))]\n",
    "            indetails.loc[len(indetails)] = [f\"Can the information be inferred?\"] + [\"\" for w in range(len(questions))]\n",
    "            indetails.loc[len(indetails)] = [f\"Do you agree with GPT's answer?\"] + [\"\" for w in range(len(questions))]\n",
    "            indetails.loc[len(indetails)] = [f\"What is your answer?\"] + [\"\" for w in range(len(questions))]\n",
    "            indetails.loc[len(indetails)] = [f\"Comments\"] + [\"\" for w in range(len(questions))]\n",
    "            try:\n",
    "                  with pd.ExcelWriter(f\"{site_id}_results_{tstamp}.xlsx\", mode='a',if_sheet_exists = 'new') as writer:\n",
    "                        indetails.T.to_excel(writer, sheet_name=f\"{row.ID}\")\n",
    "            except FileNotFoundError:\n",
    "                        indetails.T.to_excel(f\"{site_id}_results_{tstamp}.xlsx\", sheet_name=f\"{row.ID}\")\n",
    "      try:\n",
    "            with pd.ExcelWriter(f\"{site_id}_results_{tstamp}.xlsx\", mode='a',if_sheet_exists = 'new') as writer:\n",
    "                  full_responses.to_excel(writer, sheet_name='GPT-4')\n",
    "      except FileNotFoundError:\n",
    "                  full_responses.to_excel(f\"{site_id}_results_{tstamp}.xlsx\", sheet_name=\"GPT-4\")\n",
    "\n",
    "      print(f\"done {site_id}\") "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
